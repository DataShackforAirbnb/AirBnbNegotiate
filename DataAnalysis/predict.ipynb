{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "Read in the scraped calendar and insideAirbnb data\n",
    "\n",
    "Input: \n",
    "* calendar_dir: calendar data\n",
    "* inside_dir: insideAirbnb data\n",
    "\n",
    "Output:\n",
    "* df_listings: dataframe with the following variables\n",
    "    * host listing count\n",
    "    * host response rate\n",
    "    * instant bookable\n",
    "    * space shared with host\n",
    "    * usual price\n",
    "    * price variation\n",
    "    * 1-month occupancy\n",
    "    \n",
    "# Model\n",
    "Input:\n",
    "* round1_merge.json\n",
    "* round2_merge.json\n",
    "* round3_merge.json\n",
    "\n",
    "Output:\n",
    "\n",
    "\n",
    "# Predict\n",
    "\n",
    "Input:\n",
    "* X:\n",
    "    * \"1-day orphan\", \"2-day orphan\", \"3-day_orphan\", \"Within 1 week\", \"1-2 weeks in advance\", \n",
    "    * \"orp_1, adv_1\", \"orp_1, adv_2\", \"orp_2, adv_1\", \"orp_2, adv_2\", \"orp_3, adv_1\", \"orp_3, adv_2\",\n",
    "    * \"Percent off highest price\" \n",
    "    * \"Host listing count\"\n",
    "    * \"Host response rate\"\n",
    "    * \"Instant bookable\"\n",
    "    * \"Space shared with host\"\n",
    "    * \"Usual price\" x\n",
    "    * \"Price variation\" x\n",
    "    * \"1-month occupancy\" x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class All(object):\n",
    "    \n",
    "    def __init__(self, calendar_dir=None, model_dir=None, inside_dir=None, check_in=None, check_out=None, city=\"nyc\"):\n",
    "        self.inside_raw = pd.read_csv(\"listings_%s.csv\"%city)\n",
    "        self.calendar_raw = pd.read_json(\"%s_cal.json\"%city)\n",
    "        self.check_in = check_in\n",
    "        self.check_out = check_out\n",
    "        # TODAY's DATE\n",
    "        self.today_parsed = dt.datetime.today()  \n",
    "    \n",
    "    #################################################################################################################\n",
    "    def Preprocess(self):\n",
    "        # INITIALIZE GLOBAL VARIABLES\n",
    "        today_parsed = self.today_parsed\n",
    "        calendar_raw = self.calendar_raw\n",
    "        inside_raw = self.inside_raw\n",
    "       \n",
    "    \n",
    "        # CALENDAR: PARSE CALENDAR DATA INTO DATAFRAME\n",
    "        parsed_calendars = {}\n",
    "        for i in calendar_raw.keys():\n",
    "            parsed_calendars[i] = self.parse_calendar(calendar_raw[i], today_parsed)\n",
    "        listing_id = [int(key) for key in parsed_calendars.keys()]\n",
    "        df_calendar = pd.DataFrame({'id': listing_id, 'calendars': parsed_calendars.values()})        \n",
    "        \n",
    "        # CALENDAR: ADD COLUMNS FOR FUTURE CALCULATION\n",
    "        ### PRICE RELATED \n",
    "        calendar_price =  np.array([(np.median(calendar[\"price_USD\"].values), \n",
    "                                     np.std(calendar[\"price_USD\"].values), \n",
    "                                     np.max(calendar[\"price_USD\"].values)) \n",
    "                                    for calendar in df_calendar[\"calendars\"].values])\n",
    "        calendar_median_price = calendar_price[:,0]\n",
    "        calendar_price_std = calendar_price[:,1]\n",
    "        calendar_price_high = calendar_price[:,2]\n",
    "        df_calendar[\"price_median\"] = calendar_median_price\n",
    "        df_calendar[\"price_high\"] = calendar_price_high\n",
    "        df_calendar[\"price_std\"] = calendar_price_std/calendar_median_price\n",
    "        ### 1M OCCUPANCY\n",
    "        key_1m = range(30)\n",
    "        calendar_occupancy = [np.mean([calendar[\"availability\"][key] for key in key_1m]) for calendar in df_calendar[\"calendars\"].values]\n",
    "        df_calendar[\"occupancy_1m\"]=calendar_occupancy\n",
    "    \n",
    "    \n",
    "        # INSIDEAIRBNB: PREPROCESS COLUMNS\n",
    "        ### SHARED\n",
    "        shared = inside_raw[\"room_type\"].values\n",
    "        inside_raw[\"shared\"] = [x!=\"Entire home/apt\" for x in shared]\n",
    "        ### INSTANT\n",
    "        instant = inside_raw[\"instant_bookable\"].values\n",
    "        inside_raw[\"instant\"] = [x==\"t\" for x in shared]\n",
    "        ### RESPONSE RATE\n",
    "        response_imputer = Imputer(copy=True, missing_values='NaN', strategy='mean', axis=1)\n",
    "        response_num = np.array([float(response_rate.strip('%'))/100 for response_rate in inside_raw[\"host_response_rate\"].fillna(value=\"-100%\").values])\n",
    "        response_num = np.array([np.nan if x < 0 else x for x in response_num])\n",
    "        response_imputed = response_imputer.fit_transform(response_num)[0]\n",
    "        inside_raw[\"response_rate\"] = response_imputed\n",
    "    \n",
    "        # SELECT USEFUL COLUMNS FROM INSIDEAIRBNB DATA\n",
    "        inside_col = [u'id', u'response_rate', u'host_is_superhost', u'host_total_listings_count', \n",
    "                      u'number_of_reviews', u'instant', u'shared', u'beds']\n",
    "        df_listing = inside_raw[inside_col]\n",
    "\n",
    "        # MERGE CALENDAR WITH INSIDEAIRBNB DATA\n",
    "        df_merged = pd.merge(df_calendar, df_listing, on='id', how='inner')\n",
    "                \n",
    "        self.df_merged = df_merged\n",
    "        return df_merged\n",
    "    \n",
    "    # UTILITY FUNCTIONS FOR PREPROCESS\n",
    "    def parse_calendar(self, calendar, today_parsed):\n",
    "        date = []\n",
    "        price_USD = []\n",
    "        availability = []\n",
    "        min_nights = []\n",
    "        day_list = []\n",
    "        for month in calendar['calendar_months']:\n",
    "            for day in month['days']:\n",
    "                day_parsed = dt.datetime.strptime(day['date'], '%Y-%m-%d')\n",
    "                if (day_parsed > today_parsed) & (day_parsed not in day_list):\n",
    "                    date.append(day['date'])\n",
    "                    price_USD.append(day['price']['native_price'])\n",
    "                    availability.append(day['available'])\n",
    "                    min_nights.append(month['condition_ranges'][0]['conditions'][u'min_nights'])\n",
    "                day_list.append(day_parsed)\n",
    "        return pd.DataFrame({'date':date, 'price_USD': price_USD, 'availability':availability, 'min_nights': min_nights}) \n",
    "    #################################################################################################################\n",
    "    \n",
    "    #################################################################################################################\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fqian/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendars</th>\n",
       "      <th>id</th>\n",
       "      <th>price_median</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_std</th>\n",
       "      <th>occupancy_1m</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>instant</th>\n",
       "      <th>shared</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>availability        date  min_nights  price...</td>\n",
       "      <td>3309572</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>availability        date  min_nights  price...</td>\n",
       "      <td>4556118</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>availability        date  min_nights  price...</td>\n",
       "      <td>9412617</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>availability        date  min_nights  price...</td>\n",
       "      <td>1646607</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>availability        date  min_nights  price...</td>\n",
       "      <td>671765</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           calendars       id  price_median  \\\n",
       "0     availability        date  min_nights  price...  3309572            90   \n",
       "1     availability        date  min_nights  price...  4556118            36   \n",
       "2     availability        date  min_nights  price...  9412617           189   \n",
       "3     availability        date  min_nights  price...  1646607            80   \n",
       "4     availability        date  min_nights  price...   671765            29   \n",
       "\n",
       "   price_high  price_std  occupancy_1m  response_rate host_is_superhost  \\\n",
       "0          90   0.055493      1.000000           1.00                 f   \n",
       "1          36   0.000000      1.000000           0.84                 f   \n",
       "2         189   0.026184      0.300000           1.00                 f   \n",
       "3          80   0.000000      0.866667           1.00                 t   \n",
       "4          29   0.000000      1.000000           0.98                 f   \n",
       "\n",
       "   host_total_listings_count  number_of_reviews instant shared  beds  \n",
       "0                          1                 15   False   True     1  \n",
       "1                         10                  1   False   True     1  \n",
       "2                          1                  0   False  False     3  \n",
       "3                          2                 10   False   True     2  \n",
       "4                          6                 98   False   True     2  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = All(city=\"nyc\")\n",
    "test_df_calendar = test.Preprocess()\n",
    "test_df_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LDA(object):\n",
    "\n",
    "    # Initializes with the number of topics\n",
    "    def __init__(self, num_topics, num_docs, num_words, log_fac_words, log_fac_count, word):\n",
    "        self.num_topics = num_topics\n",
    "        self.num_docs = num_docs\n",
    "        self.num_words = num_words\n",
    "        self.log_fac_words = log_fac_words\n",
    "        self.log_fac_count = log_fac_count\n",
    "\n",
    "        # initialize theta_k ~ Dirichlet(alpha)\n",
    "        # theta = (1 * k)\n",
    "        alphas = np.random.gamma(1, 1) * np.random.dirichlet([1.] * num_topics)\n",
    "#         alphas = np.random.randint(1, 11, size=num_topics)\n",
    "        self.theta = np.random.dirichlet(alphas)\n",
    "\n",
    "        # initialize beta_k,v ~ Dirichlet(alpha), each topic k sum up to 1\n",
    "        # beta = (k * v)\n",
    "        beta = np.zeros((num_topics, num_words))\n",
    "        alphas = np.random.randint(1, 11, size=(num_topics, num_words))\n",
    "        for k in range(num_topics):\n",
    "#             alphas = np.random.gamma(1, 1) * np.random.dirichlet([1.] * num_words) + 1.00\n",
    "            beta[k] = np.random.dirichlet(alphas[k])\n",
    "        self.beta = beta\n",
    "\n",
    "        # save w matrix\n",
    "        # word = (d * v)\n",
    "        self.sparse_w = word\n",
    "\n",
    "\n",
    "    # This should run the M step of the EM algorithm\n",
    "    def M_step(self):\n",
    "        # ==============\n",
    "        # Update Theta\n",
    "        # ==============\n",
    "        self.theta = np.sum(self.sparse_gamma.toarray(), axis=0)*1.0/num_docs\n",
    "\n",
    "        # ===============\n",
    "        # Update Beta\n",
    "        # ===============\n",
    "        before_marginalize = self.sparse_gamma.transpose().dot(self.sparse_w).toarray() + 10**-10\n",
    "        denominator_one_column = np.sum(before_marginalize, axis=1)\n",
    "        denominator = np.tile(denominator_one_column.reshape((self.num_topics, 1)), (1, self.num_words))\n",
    "        beta = before_marginalize*1.0/denominator\n",
    "        self.beta = beta\n",
    "#         print beta[0]\n",
    "\n",
    "\n",
    "    # This should run the E step of the EM algorithm\n",
    "    # compute gamma(z_dk)\n",
    "    def E_step(self):\n",
    "        before_marginalize = np.tile(np.log(self.theta), (self.num_docs, 1))\\\n",
    "                             + self.sparse_w.dot(np.transpose(np.log(self.beta)))\n",
    "#                              + np.tile(self.log_fac_words, (1, self.num_topics))\\\n",
    "#                              - np.tile(self.log_fac_count, (1, self.num_topics))\n",
    "\n",
    "\n",
    "        log_gamma_denom = scipy.misc.logsumexp(before_marginalize, axis=1)\n",
    "        log_gamma = before_marginalize - np.tile(log_gamma_denom.reshape((self.num_docs, 1)), (1, self.num_topics))\n",
    "        gamma = np.exp(log_gamma)\n",
    "        self.sparse_gamma = sparse.csr_matrix(gamma)\n",
    "\n",
    "    # This function repeats E and M step\n",
    "    def run_ME(self):\n",
    "        log_lik_list = []\n",
    "        # run for first 2 rounds\n",
    "        self.E_step()\n",
    "        self.M_step()\n",
    "        log_lik_list.append(self.compute_log_likelihood())\n",
    "        self.E_step()\n",
    "        self.M_step()\n",
    "        log_lik_list.append(self.compute_log_likelihood())\n",
    "\n",
    "        while abs(log_lik_list[-2] - log_lik_list[-1]) >1:\n",
    "            self.E_step()\n",
    "            self.M_step()\n",
    "            log_lik_list.append(self.compute_log_likelihood())\n",
    "        self.log_lik_list = log_lik_list\n",
    "\n",
    "    def compute_log_likelihood(self):\n",
    "        w_log_beta = self.sparse_w.dot(np.transpose(np.log(self.beta))) # (d, k)\n",
    "        log_theta = np.tile(self.theta, (self.num_docs, 1))\n",
    "        log_theta_w_log_beta = log_theta + w_log_beta\n",
    "        return np.sum(self.sparse_gamma.multiply(log_theta_w_log_beta))\n",
    "\n",
    "    def plot_objective_function(self):\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.plot(self.log_lik_list)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"log likelihood\")\n",
    "\n",
    "    # This should print the topics that you find\n",
    "    # by listing the most likely words\n",
    "    def print_topics(self, num_representing_words=10):\n",
    "        for k in range(self.num_topics):\n",
    "            ordered_index = np.argsort(self.beta[k])[::-1]\n",
    "            print \"=============== TOPIC %i ===============\"%(k+1)\n",
    "            for i in range(num_representing_words):\n",
    "                print word_dict_lines[ordered_index[num_representing_words - i-1]].rstrip()\n",
    "            print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
